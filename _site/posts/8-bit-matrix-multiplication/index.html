<!DOCTYPE html>









<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en"
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

    

    

  

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale 정리" />
<meta name="author" content="Juhong Song" />
<meta property="og:locale" content="en" />
<meta name="description" content="1. Introduction" />
<meta property="og:description" content="1. Introduction" />
<link rel="canonical" href="http://localhost:4000/posts/8-bit-matrix-multiplication/" />
<meta property="og:url" content="http://localhost:4000/posts/8-bit-matrix-multiplication/" />
<meta property="og:site_name" content="Juhong Song" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-02-12T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale 정리" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Juhong Song","url":"https://github.com/jhss"},"dateModified":"2023-02-12T23:25:44+09:00","datePublished":"2023-02-12T00:00:00+09:00","description":"1. Introduction","headline":"LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale 정리","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/8-bit-matrix-multiplication/"},"url":"http://localhost:4000/posts/8-bit-matrix-multiplication/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale 정리 | Juhong Song
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Juhong Song">
<meta name="application-name" content="Juhong Song">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  

    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">

  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>

  
    <!--
  Switch the mode between dark and light.
-->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() { return "mode"; }
    static get MODE_ATTR() { return "data-mode"; }
    static get DARK_MODE() { return "dark"; }
    static get LIGHT_MODE() { return "light"; }
    static get ID() { return "mode-toggle"; }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener("change", () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }

          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();

      });

    } /* constructor() */

    get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); }

    get isSysDarkPrefer() { return this.sysDarkPrefers.matches; }

    get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; }

    get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; }

    get hasMode() { return this.mode != null; }

    get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode
        || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      $('html').removeAttr(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage({
        direction: ModeToggle.ID,
        message: this.modeStatus
      }, "*");
    }

  } /* ModeToggle */

  const toggle = new ModeToggle();

  function flipMode() {
    if (toggle.hasMode) {
      if (toggle.isSysDarkPrefer) {
        if (toggle.isLightMode) {
          toggle.clearMode();
        } else {
          toggle.setLight();
        }

      } else {
        if (toggle.isDarkMode) {
          toggle.clearMode();
        } else {
          toggle.setDark();
        }
      }

    } else {
      if (toggle.isSysDarkPrefer) {
        toggle.setLight();
      } else {
        toggle.setDark();
      }
    }

    toggle.notify();

  } /* flipMode() */

</script>

  
</head>


  <body data-spy="scroll" data-target="#toc" data-topbar-visible="true">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" class="mx-auto">
        
          
          <img src="/assets/img/avatar.png" alt="avatar" onerror="this.style.display='none'">
        
      </a>
    </div>

    <div class="site-title">
      <a href="/">Juhong Song</a>
    </div>
    <div class="site-subtitle font-italic"></div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">

    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/categories/" class="nav-link">
        <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tags/" class="nav-link">
        <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>TAGS</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/archives/" class="nav-link">
        <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/about/" class="nav-link">
        <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center">

    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
      <a href="https://github.com/jhss" aria-label="github"
        target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
      

    
      

      
      <a href="
          javascript:location.href = 'mailto:' + ['mtvfc','naver.com'].join('@')" aria-label="email"
        >
        <i class="fas fa-envelope"></i>
      </a>
      

    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper">
  <div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4">
    <span id="breadcrumb">

    

    

      

        
          <span>
            <a href="/">
              Home
            </a>
          </span>

        

      

        

      

        

          
            <span>LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale 정리</span>
          

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" autocomplete="off" placeholder="Search...">
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container pl-xl-4 pr-xl-4">
        





<div class="row">

  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4">
    <div class="post pl-1 pr-1 pl-md-2 pr-md-2">

    

    
      
      
        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->




  
  

  
    
      
      
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  

  



<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  

  
  

  




<!-- Wrap prompt element of blockquote with the <div> tag -->







<!-- return -->


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>




<h1 data-toc-skip>LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale 정리</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      Posted
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1676127600"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Feb 12, 2023
</em>

    </span>

    <!-- lastmod date -->
    
    <span>
      Updated
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1676211944"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Feb 12, 2023
</em>

    </span>
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      By

      <em>
      
        
          <a href="https://github.com/jhss">Juhong Song</a>
          
        
      
      </em>
    </span>

    <div>
      <!-- page views -->
      

      <!-- read time -->
      <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->



<!-- words per minute  -->










<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom"
  title="2375 words">
  <em>13 min</em> read</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <h2 id="1-introduction"><span class="mr-2"><strong>1. Introduction</strong></span><a href="#1-introduction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Large pre-trained 언어모델에 대해서 8-bit quantization을 적용하는 기법들이 많이 연구되었지만, 이런 기법들은 350M 이하 스케일에 대해서만 연구되는 경우가 많았습니다. 이 논문에서는 performance 감소없이 billion 단위에서도 적용 가능한 quantization 기법을 제시합니다.</p>

<p>이 논문에서는 파라미터 스케일이 6B정도가 되었을 때 Transformer에만 나타나는 특이한 현상이 있다고 합니다. 트랜스포머 레이어 전체에서 25% 정도에서만 관찰이 된다고 하는데, 특정 차원의 feature 크기가 다른 차원의 feature 크기보다 20배정도 크게 나타난다고 합니다.</p>

<p>Transformer에서만 관측되는 특이한 현상을 분석하기 위해서 논문에서는 13B parameter를 가진 모델에 대해서 feature 차원의 크기를 비교했고, 값이 6보다 큰 feature를 outlier로 간주했습니다. 그리고 실험을 할 때 특정 library에 있는 오류로 인한 영향을 없애기 위해서 3개의 software(OpenAI, Fairseq, EleutherAI)에 구현된 GPT-2 model을 모두 사용해서 실험을 진행했습니다.</p>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 600 600'%3E%3C/svg%3E" data-src="http://localhost:4000/assets/img/57.PNG" alt="57.PNG" width="600" height="600" data-proofer-ignore></p>

<p>위의 그림 (a)는 모델 파라미터 수를 늘림에따라 outlier로 인해 영향을 받는 sequence의 비율을 측정한 것입니다. 예를들어 sequence의 i번째 단어에 특정 차원에 outlier가 등장했는데, 해당 outlier가 다른 단어에 얼마나 영향을 끼치는지를 측정한 값입니다. 그림을 보면 파라미터 수가 6B에서 6.5B로 넘어갈 때 영향을 받는 비율이 급격히 증가한다는 것을 볼 수 있습니다.</p>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 700 700'%3E%3C/svg%3E" data-src="http://localhost:4000/assets/img/56.PNG" alt="56.PNG" width="700" height="700" data-proofer-ignore></p>

<p>위에 그림 (a)에서는 perplexity가 감소할수록 outlier feature의 median magnitude값이 커지는 것을 관찰할 수 있는데, 이로 인해 transformer에 Int8 quantization을 적용했을 때 성능이 좋지 않습니다. 왜냐하면 특정 feature의 값이 커지면 quantization range가 커져서 대부분 quantization bin은 비어있는 상태가 되고, 원래 값이 작았던 feature는 0에 가까운 값으로 quantization이 진행되기 때문에 정보 손실이 많이 발생하게 됩니다. 또한 Int8 quantization 뿐만 아니라 16-bit quantization 방법도 마찬가지로 6.7B scale을 넘어가면 outlier로 인해 잘 작동하지 않을 것이라고 논문에서 주장합니다.</p>

<p>또한 그림(b)에서는 perplexity가 감소함에 따라 outlier feature 개수가 증가하는 것을 볼 수 있습니다. 논문에서는 6.7B transformer에서 2,048 sequence 기준으로 150k 정도의 outlier feature를 관측했다고 하는, 이런 outlier들은 6개의 hidden dimension에 집중되어있다고 합니다.</p>

<p>이런 outlier는 transformer performance에 큰 영향을 끼치는데, 만약 이 7개의 차원을 제거하면 top-1 softmax probability값이 40%에서 20%로 줄어들고, vadliation perplexity 값이 600~1,000% 증가한다고 합니다. 만약에 임의의 7개의 차원을 제거한다면 top-1 probability는 0.02~0.3% 만큼 감소하고 perplexity는 0.1%만큼 증가한다고 하는데, 이런 실험은 outlier feature가 성능에 얼마나 중요한 역할을 하는지 나타냅니다. 그래서 이런 outlier feature들에 대해서 좀 더 quantization precision을 높이면 large scale transformer에서도 모델의 성능을 유지한 채 quantization 기법을 적용할 수 있게 될거라고 논문에서 주장하고 있습니다.</p>

<p>이 논문에서 제시한 기법은 앞서 관측된 outlier를 고려해서 quantization 기법을 수행하는 방법입니다. 방법을 요약하자면 outlier feature 차원에 대해서는 16-bit quantization 기법을 적용하고, 그 외의 차원에 대해서는 8-bit quantization을 적용하는 방법입니다.</p>

<h2 id="2-background"><span class="mr-2"><strong>2. Background</strong></span><a href="#2-background" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<h3 id="21-8-bit-data-types-and-quantization"><span class="mr-2"><strong>2.1. 8-Bit Data Types and Quantization</strong></span><a href="#21-8-bit-data-types-and-quantization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><strong>Absmax quantization</strong>은 입력을 8-bit 범위 \([-127,127]\)로 바꾸는 방법인데, 127을 곱하고 입력 tensor의 infinity norm으로 나눠주는 방식으로 다음과 같이 계산합니다. 여기서 \(\lfloor \rceil\)은 반올림을 나타냅니다.</p>

\[\mathbf{X}_{i 8}=\left\lfloor\frac{127 \cdot \mathbf{X}_{f 16}}{\max _{i j}\left(\left|\mathbf{X}_{f 16_{i j} \mid}\right|\right)}\right\rfloor=\left\lfloor\frac{127}{\left\|\mathbf{X}_{f 16}\right\|_{\infty}} \mathbf{X}_{f 16}\right\rceil=\left\lfloor s_{x_{f 16}} \mathbf{X}_{f 16} \mid\right.\]

<p><strong>Zeropoint quantization</strong>은 입력 분포를 normalized dynamic range \(nd_x\)만큼 scale한 후에 zeropoint \(zp_x\)만큼 이동시키는 방법입니다. 입력이 asymmetric distribution인 경우에, Absmax를 사용하면 일부 bit만 사용해서 quantization이 진행되는데, zeropoint 방법을 상요하면 전체 bit를 다 사용해서 입력데이터를 표현할 수 있습니다.</p>

<h2 id="3-int8-matrix-multiplication-at-scale"><span class="mr-2"><strong>3. Int8 Matrix Multiplication at scale</strong></span><a href="#3-int8-matrix-multiplication-at-scale" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>단일 scaling constant로 quantization을 수행할 때 문제점은 tensor안에 outlier가 1개라도 존재하면 tensor안에 다른 값들의 quantization precision을 감소시킬 수 있기 때문입니다. 그래서 tensor를 여러 block으로 나누고 각 block마다 다르게 scailing factor를 계산하면 outlier의 영향을 block 안으로 한정시킬 수 있습니다. 이 논문에서는 tensor를 vector 단위로 나눠서 outlier의 영향을 줄였습니다.</p>

<h3 id="31-vector-wise-quantization"><span class="mr-2"><strong>3.1. Vector-wise Quantization</strong></span><a href="#31-vector-wise-quantization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>Hidden states \(\mathbf{X}_{f 16} \in \mathbb{R}^{b \times h}\)와 weight matrix \(\mathbf{W}_{f 16} \in \mathbb{R}^{h \times o}\)를 곱하는 상황에서, \(\mathbf{X}_{f 16}\)의 각 row에 다른 scale constant \(c_{x_{f 16}}\)를 할당하고, \(\mathbf{W}_{f 16}\)의 각 column에 다른 scale constant \(\mathbf{c}_{w_{f 16}}\)를 할당해서 quantization을 수행하면, dequantize를 할 때 \(c_{x_{f 16}}\)와 \(\mathbf{c}_{w_{f 16}}\)의 outer product를 이용할 수 있습니다. 그래서 Vector-wise quantization을 통해 Int8 matrix multiplication을 수행하는 과정을 다음과 같이 나타낼 수 있습니다.</p>

\[\mathbf{X}_{f 16} \mathbf{W}_{f 16}=\mathbf{C}_{f 16} \approx \frac{1}{\mathbf{c}_{x_{f 16}} \otimes \mathbf{c}_{w_{f 16}}} \mathbf{C}_{i 32}=S \cdot \mathbf{C}_{i 32}=\mathbf{S} \cdot \mathbf{A}_{i 8} \mathbf{B}_{i 8}=\mathbf{S} \cdot Q\left(\mathbf{A}_{f 16}\right) Q\left(\mathbf{B}_{f 16}\right)\]

<p>16-bit floating point precision을 가진 두 행렬 \(A, B\)를 곱할 때, 앞서 말한 vector-wise scale factor를 통해 quantization을 수행해서 int8로 변환하고, 변환한 행렬을 곱하고 다시 scale factor의 outer product로 나눠주면 원래 float 16으로 행렬곱 한 것을 근사하게 됩니다.</p>

<h3 id="32-the-core-of-llmint8-mixed-precision-decomposition"><span class="mr-2"><strong>3.2. The core of LLM.int8(): Mixed-precision Decomposition</strong></span><a href="#32-the-core-of-llmint8-mixed-precision-decomposition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>위에서 large scale transformer의 outlier를 분석한 결과에 따르면, outlier는 특정 feature 차원에 집중되어 있기 때문에 outlier가 없는 차원에만 quantization을 하면 성능을 유지한 채 quantization 기법을 적용할 수 있다고 합니다.</p>

<p>그래서 feature 차원 중에서 값이 6.0 이상인 feature의 차원을 \(O=\{i \mid i \in \mathbb{Z}, 0 \leq i \leq h\}\)에 집어넣고, 이 집합에 속한 차원에 대해서는 float 16 행렬곱을 수행하고, 나머지 차원에 대해서는 int8 vector-wise quantization을 적용해서 행렬곱을 수행합니다.</p>

\[\mathbf{C}_{f 16} \approx \sum_{h \in O} \mathbf{X}_{f 16}^h \mathbf{W}_{f 16}^h+\mathbf{S}_{f 16} \cdot \sum_{h \notin O} \mathbf{X}_{i 8}^h \mathbf{W}_{i 8}^h\]

<p>이런 방식이 효과적인 이유는 outlier 차원의 비율이 0.1% 정도이기 때문에, 나머지 99.9%의 차원에 대해서는 메모리 측면에서 효율적인 8-bit 행렬곱을 할 수 있기 떄문입니다.</p>

<h2 id="4-experiment"><span class="mr-2"><strong>4. Experiment</strong></span><a href="#4-experiment" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>이 논문에서는 2개의 실험을 했는데 large scale transformer에 대해서 language modeling 성능과 zero shot accuracy 성능을 기존의 quantization 기법과 비교했습니다. 먼저 Language Modeling 성능은 파라미터 수를 점점 증가시킴에 따라 perplexity 값을 기존의 quantization 기법과 비교를 하는 방식으로 진행했습니다. 데이터는 C4 corpus validation data를 사용했습니다.</p>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 500 500'%3E%3C/svg%3E" data-src="http://localhost:4000/assets/img/58.PNG" alt="58.PNG" width="500" height="500" data-proofer-ignore></p>

<p>실험 결과를 보면 다른 quantization 기법들은 6.7B scale 이후에 fp32와 비교해서 perplexity 값이 커졌다는 결과가 나타나는데, 논문에서 제시한 방법은 fp32와 비교해서도 perplexity 값이 거의 차이가 나지 않는 결과가 나타났습니다.</p>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 500 500'%3E%3C/svg%3E" data-src="http://localhost:4000/assets/img/54.PNG" alt="54.PNG" width="500" height="500" data-proofer-ignore></p>

<p>그 다음에 OPT model을 사용해서 zero shot accuracy 성능을 비교했는데, 그림을 보면 스케일이 2.7B보다 작을 때는 기존의 8-bit quantization 기법과 논문에서 제시한 기법이 성능이 비슷하지만, 6.7B 정도 스케일이 되었을 때는 성능 차이가 많이 나는 결과가 나타났습니다.</p>

<h2 id="5-discussion-and-limitations"><span class="mr-2"><strong>5. Discussion and Limitations</strong></span><a href="#5-discussion-and-limitations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>이 논문에서는 transfomer의 특징을 분석해서 multi-billion scale에 대해서도 잘 작동하는 Int8 quantization 기법을 제시했습니다. 이 방법의 한계는 Int8 data type에만 적용이 가능하단 점인데, Int8로 굳이 한 이유는 현재 GPU와 TPU가 8-bit 중에서 int type만 지원하기 때문입니다. 현재 GPU와 TPU가 8-bit floating point를 지원하지 않기 때문에, 이 방법은 연구하지 않았다고 합니다.</p>

<p>또한 스케일이 175B 까지만 한정되어 있는데, 그 이상 모델이 커지면 다른 추가적인 특성 때문에 논문에서 제시한 quantization 기법이 잘 적용되지 않을 수도 있다고 합니다. 마지막으로 논문에서 제시한 기법은 attention function에는 적용하지 않았는데, 그 이유가 attention function에는 parameter가 포함되지 않아서 quantization을 적용해도 메모리 사용량 감소가 일어나지 않기 때문이라고 합니다.</p>

</div>



<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw mr-1"></i>
    
      <a href='/categories/model-compression/'>Model Compression</a>,
      <a href='/categories/quantization/'>Quantization</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw mr-1"></i>
      
      <a href="/tags/model-compression/"
          class="post-tag no-text-decoration" >Model Compression</a>
      
      <a href="/tags/quantization/"
          class="post-tag no-text-decoration" >Quantization</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.

      
    </div>

    <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=LLM.int8%28%29%3A+8-bit+Matrix+Multiplication+for+Transformers+at+Scale+%EC%A0%95%EB%A6%AC+-+Juhong+Song&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2F8-bit-matrix-multiplication%2F" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=LLM.int8%28%29%3A+8-bit+Matrix+Multiplication+for+Transformers+at+Scale+%EC%A0%95%EB%A6%AC+-+Juhong+Song&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2F8-bit-matrix-multiplication%2F" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2F8-bit-matrix-multiplication%2F&text=LLM.int8%28%29%3A+8-bit+Matrix+Multiplication+for+Transformers+at+Scale+%EC%A0%95%EB%A6%AC+-+Juhong+Song" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    

    <i id="copy-link" class="fa-fw fas fa-link small"
        data-toggle="tooltip" data-placement="top"
        title="Copy link"
        data-title-succeed="Link copied successfully!">
    </i>

  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


	    <div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */

    var disqus_config = function () {
    this.page.url = 'https://jhss.github.io';  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = 'https://jhss.github.io'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };

    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://jhss-github-io.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>




      
    
    

    </div>
  </div> <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 pl-2 text-muted">

    <div class="access">
      















  <div id="access-lastmod" class="post">
    <div class="panel-heading">Recently Updated</div>
    <ul class="post-content pl-0 pb-1 ml-1 mt-2">
      
        
        
        
      <li><a href="/posts/8-bit-optimizer/">8-bit Optimizers via Block-wise Quantization 정리</a></li>
      
        
        
        
      <li><a href="/posts/8-bit-matrix-multiplication/">LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale 정리</a></li>
      
        
        
        
      <li><a href="/posts/Sparsity-in-Deep-Learning-Pruning-and-growth/">Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks 정리 (Chapter 1 ~ 3)</a></li>
      
        
        
        
      <li><a href="/posts/A-Comprehensive-Survey-on-Graph-Neural-Networks/">A Comprehensive Survey on Graph Neural Networks 정리</a></li>
      
        
        
        
      <li><a href="/posts/Recent-Advances-on-Neural-Network-Pruning-at-Init/">Recent Advances on Neural Network Pruning at Initialization 정리</a></li>
      
    </ul>
  </div> <!-- #access-lastmod -->



      















  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/model-compression/">Model Compression</a>
    
      
      <a class="post-tag" href="/tags/quantization/">Quantization</a>
    
      
      <a class="post-tag" href="/tags/pruning/">Pruning</a>
    
      
      <a class="post-tag" href="/tags/graph-neural-network/">Graph Neural Network</a>
    

    </div>
  </div>


    </div>

    
      
      



<!-- BS-toc.js will be loaded at medium priority -->
<script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script>

<div id="toc-wrapper" class="pl-0 pr-4 mb-5">
  <div class="panel-heading pl-3 pt-2 mb-2">Contents</div>
  <nav id="toc" data-toggle="toc"></nav>
</div>


    
  </div>

</div>

<!-- tail -->

<div class="row">
  <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5">
    
      
      <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->





  <div id="related-posts" class="mb-2 mb-sm-4">
    <h3 class="pt-2 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
    <div class="card-deck mb-4">
    
      
      
      <div class="card">
        <a href="/posts/A-survey-of-Quantization-Methods-for-Efficient-Neual-Network-Inference/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1671807600"
    data-df="ll"
    >
  Dec 24, 2022
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>A survey of Quantization Methods for Efficient Neural Network 정리</h3>
            <div class="text-muted small">
              <p>
                





                1. Neural Network 최적화 연구방향들

1.1.  효율적인 네트워크 설계

Micro-architecture 관점에서는 kernel type을 depth-wise convolution 혹은 low-rank factorization을 사용하는 방법이 있고, Macro-architecture 관점에서는 residual, inception 같은...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/8-bit-optimizer/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1674918000"
    data-df="ll"
    >
  Jan 29, 2023
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>8-bit Optimizers via Block-wise Quantization 정리</h3>
            <div class="text-muted small">
              <p>
                





                1. Introduction

Momentum이나 Adam optimizer는 시간에 따른 gradient 통계량 정보를 이용해서 다음 그레디언트를 업데이트할 때 그레디언트의 방향을 조절하거나 학습률을 조절합니다. 이런 방식은 일반적인 SGD optimizer에 비해서 학습을 가속화 시켜준다는 장점이 있지만, gradient 통계량 정보를 계속 가지고...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/Recent-Advances-on-Neural-Network-Pruning-at-Init/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1672498800"
    data-df="ll"
    >
  Jan  1, 2023
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Recent Advances on Neural Network Pruning at Initialization 정리</h3>
            <div class="text-muted small">
              <p>
                





                1. Introduction

기존의 Pruning 기법은 pretrained model에 적용하는 방법이 대부분이었습니다. 하지만 최근에는 임의로 초기화된 네트워크 (a randomly initialized network)에 pruning 기법을 적용하는 방법들이 연구되고 있습니다. 이 기법을 Pruning at Initialization (PaI)...
              </p>
            </div>
          </div>
        </a>
      </div>
    
    </div> <!-- .card-deck -->
  </div> <!-- #related-posts -->


    
      
      <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/posts/8-bit-optimizer/" class="btn btn-outline-primary"
    prompt="Older">
    <p>8-bit Optimizers via Block-wise Quantization 정리</p>
  </a>
  

  
  <div class="btn btn-outline-primary disabled"
    prompt="Newer">
    <p>-</p>
  </div>
  

</div>

    
      
      <!--  The comments switcher -->

  
  <!--
  The Disqus lazy loading.
-->
<div id="disqus_thread" class="pt-2 pb-2">
  <p class="text-center text-muted small">
    Comments powered by <a href="https://disqus.com/">Disqus</a>.
  </p>
</div>

<script type="text/javascript">

  var disqus_config = function () {
    this.page.url = 'http://localhost:4000/posts/8-bit-matrix-multiplication/';
    this.page.identifier = '/posts/8-bit-matrix-multiplication/';
  };

  /* Lazy loading */
  var disqus_observer = new IntersectionObserver(function (entries) {
    if(entries[0].isIntersecting) {
        (function () {
            var d = document, s = d.createElement('script');
            s.src = 'https://jhss-github-io.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();

        disqus_observer.disconnect();
    }
  }, { threshold: [0] });

  disqus_observer.observe(document.querySelector('#disqus_thread'));

  /* Auto switch theme */
  function reloadDisqus() {
    if (event.source === window && event.data &&
      event.data.direction === ModeToggle.ID) {
      /* Disqus hasn't been loaded */
      if (typeof DISQUS === "undefined") {
        return;
      }

      if (document.readyState == 'complete') {
        DISQUS.reset({ reload: true, config: disqus_config });
      }
    }
  }

  const modeToggle = document.querySelector(".mode-toggle");

  if (typeof modeToggle !== "undefined") {
    window.addEventListener("message", reloadDisqus);
  }

</script>



    
  </div>
</div>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      















  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/model-compression/">Model Compression</a>
    
      
      <a class="post-tag" href="/tags/quantization/">Quantization</a>
    
      
      <a class="post-tag" href="/tags/pruning/">Pruning</a>
    
      
      <a class="post-tag" href="/tags/graph-neural-network/">Graph Neural Network</a>
    

    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    <!-- The Footer -->

<footer>
  <div class="container pl-lg-4 pr-lg-4">
    <div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3">
      <div class="footer-left">
        <p class="mb-0">
          © 2023
          <a href="https://github.com/jhss">juhong</a>.
          
          <span data-toggle="tooltip" data-placement="top"
            title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
          
        </p>
      </div>

      <div class="footer-right">
        <p class="mb-0">

          

          

          Powered by 
          <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
           with 
          <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>
           theme.
        </p>
      </div>
    </div>
  </div>
</footer>


    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    
      <div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true"
        data-animation="true" data-autohide="false">
        <div class="toast-header">
          <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close">
            <span aria-hidden="true">&times;</span>
          </button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="pl-2 pr-2 mb-3">A new version of content is available.</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            Update
          </button>
        </div>
      </div>
    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No results found.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


    <!--
  JS selector for site.
-->

<!-- layout specified -->


  



  <!-- image lazy-loading & popup & clipboard -->
  

  







  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script>







  

  

  







  
    

    

  



  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script>








<script defer src="/assets/js/dist/post.min.js"></script>



<!-- commons -->

<script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script>




  </body>

</html>

